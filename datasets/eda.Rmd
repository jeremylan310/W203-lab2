---
title: "EDA"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Research paper here: http://www.math-evry.cnrs.fr/_media/members/aguilloux/enseignements/m1mint/moro2016.pdf

Dataset here: https://archive-beta.ics.uci.edu/ml/datasets/facebook+metrics

## Imports

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(tidyverse)
library(ggplot2)
library(grid)
library(gridExtra)
library(sandwich) # need to install
library(lmtest)   # need to install
library(stargazer)
```

## Read data

```{r}
# read data as is
fb_data = read_delim("./dataset_Facebook.csv", delim=";")

# change col names
cols = c(
  "page_ttl_likes",
  "type",
  "category",
  "post_month",
  "post_wkday",
  "post_hour",
  "paid",
  "lifetime_post_reach",
  "lifetime_post_impressions",
  "lifetime_engaged_users",
  "lifetime_post_consumers",
  "lifetime_post_consumptions",
  "lifetime_post_impressions_from_page_have_likeds",
  "lifetime_post_impressions_from_page_likes",
  "lifetime_people_liked_engaged_with_post",
  "comments",
  "likes",
  "shares",
  "interactions"
)
colnames(fb_data) = cols

fb_data = fb_data %>%
  mutate(
    day_period=case_when(
      post_hour >= 1  & post_hour <= 5  ~ "overnight",
      post_hour >= 6  & post_hour <= 11 ~ "morning",
      post_hour >= 12 & post_hour <= 17 ~ "afternoon",
      post_hour >= 18 & post_hour <= 23 ~ "evening"
    )
  )

fb_data = fb_data %>%
  mutate(
    media_type=case_when(
      type == "Video" ~ "media",
      type == "Photo" ~ "media",
      TRUE            ~ "non-media"
    )
  )

summary(fb_data)
```

## EDA

### Output variables


#### Engagement
Based on the paper, we can have the post's engaged users as output. The variable has a strong right skewed distribution, so we could potentially apply a log transformation. This would allow us to normalize the variable, minimize the outliers and interpret the coefficient as changes in the % of the variable, not the absolute values:
```{r echo=FALSE}
p1 = fb_data %>% ggplot() +
  aes(x=lifetime_engaged_users) +
  geom_histogram(bins=20) +
  labs(x="Engaged Users")

p2 = fb_data %>% ggplot() +
  aes(x=log(lifetime_engaged_users)) +
  geom_histogram(bins=20) +
  labs(x="Lof of Engaged Users")

pb = fb_data %>% ggplot() +
  aes(x=lifetime_engaged_users) +
  geom_boxplot() +
  labs(x="Engaged users")

pb2 = fb_data %>% ggplot() +
  aes(x=log(lifetime_engaged_users)) +
  geom_boxplot() +
  labs(x="Log of Engaged Users")

grid.arrange(p1, pb, p2, pb2, ncol=2, nrow=2, top="Histogram and boxplot for the post's engaged users (normal and log)")
```



The paper actually runs the analysis by trying to predict 12 different variables using 7 inputs. I'll add a few other graphs here:


#### Interactions
Interactions is the sum of likes, shares and comments:
```{r}
p1 = fb_data %>% ggplot() +
  aes(x=interactions) +
  geom_histogram(bins=20) +
  labs(x="Interactions")

p2 = fb_data %>% ggplot() +
  aes(x=log(interactions)) +
  geom_histogram(bins=20) +
  labs(x="Log of Interactions")

pb = fb_data %>% ggplot() +
  aes(x=interactions) +
  geom_boxplot() +
  labs(x="Interactions")

pb2 = fb_data %>% ggplot() +
  aes(x=log(interactions)) +
  geom_boxplot() +
  labs(x="Log of Interactions")

grid.arrange(p1, pb, p2, pb2, ncol=2, nrow=2, top="Histogram and boxplot for post interactions (normal and log)")
```


#### Reach
Number of people the post reached:
```{r}
p1 = fb_data %>% ggplot() +
  aes(x=lifetime_post_reach) +
  geom_histogram(bins=20)

p2 = fb_data %>% ggplot() +
  aes(x=log(lifetime_post_reach)) +
  geom_histogram(bins=20)

grid.arrange(p1, p2, ncol=2)
```




#### Comments
```{r}
p1 = fb_data %>% ggplot() +
  aes(x=comments) +
  geom_histogram(bins=20)

p2 = fb_data %>% ggplot() +
  aes(x=log(comments)) +
  geom_histogram(bins=20)

grid.arrange(p1, p2, ncol=2)
```


#### Likes
```{r}
p1 = fb_data %>% ggplot() +
  aes(x=likes) +
  geom_histogram(bins=20)

p2 = fb_data %>% ggplot() +
  aes(x=log(likes)) +
  geom_histogram(bins=20)

grid.arrange(p1, p2, ncol=2)
```


#### Shares
```{r}
p1 = fb_data %>% ggplot() +
  aes(x=shares) +
  geom_histogram(bins=20)

p2 = fb_data %>% ggplot() +
  aes(x=log(shares)) +
  geom_histogram(bins=20)

grid.arrange(p1, p2, ncol=2)
```



#### Brand Awareness

Tae also proposed using the brand awareness as an output variable, which could be a nice twist to what was done on the paper:

```{r}
p1 = fb_data %>% ggplot() +
  aes(x=page_ttl_likes) +
  geom_histogram(bins=20)

p2 = fb_data %>% ggplot() +
  aes(x=log(page_ttl_likes)) +
  geom_histogram(bins=20)

grid.arrange(p1, p2, ncol=2)
```


### Explanatory variables

The paper uses 7 variables to try to explain 12 outcome ones (most of them explained above)


#### Brand Awareness

This would be the main variable we would like to understand the impact. It is expressed in the number of likes the FB page of the company had when the post was published:

```{r}
p1 = fb_data %>% ggplot() + 
  aes(x=page_ttl_likes) + 
  geom_histogram(bins=20, color="blue", fill="blue", alpha=0.5)

p2 = fb_data %>% ggplot() + 
  aes(x=page_ttl_likes, y=lifetime_engaged_users) + 
  geom_point(alpha=0.3, fill="blue", color="blue")


grid.arrange(p1, p2, ncol=2)
```

Surprisingly, it displays a low negative correlation, although it may be the case that the relationship is not linear:
```{r}
cor(fb_data$page_ttl_likes, fb_data$lifetime_engaged_users)
```


Running a simple linear regression of this, the coefficient is significant to 5% level (assuming homoscedasticity):

```{r}
mod = lm(lifetime_engaged_users ~ 1 + page_ttl_likes, data=fb_data)
summary(mod)
```

Heteroscedastic test:

```{r}
coeftest(mod, vcov=vcovHC(mod, type="HC1"))
```

A log-level model the coeff is very signficant:

```{r}
loglev_mod = lm(I(log(lifetime_engaged_users)) ~ 1 + page_ttl_likes, data=fb_data)
summary(loglev_mod)
```

And the heteroscedastic test:
```{r}
coeftest(loglev_mod, vcov=vcovHC(loglev_mod, type="HC1"))
```


Same with the log-log model. This may be better as it is easier to interpret:

```{r}
loglog_mod = lm(I(log(lifetime_engaged_users)) ~ 1 + I(log(page_ttl_likes)), data=fb_data)
summary(loglog_mod)
```


And the hetesk test:
```{r}
coeftest(loglog_mod, vcov=vcovHC(loglog_mod, type="HC1"))
```

#### Category

This is the category of the post, related to the kind of content it has. Coded in 3 values:

  1. Action: Special offers and contests
  2. Inspiration: Direct advertisement, explicit brand content
  3. Inspiration: Non-explicit brand related content

```{r}
p1 = fb_data %>% ggplot() + 
  aes(x=category) + 
  geom_bar(width=0.5, alpha=0.5, fill="blue", color="blue")

p2 = fb_data %>% ggplot() + 
  aes(x=category, y=lifetime_engaged_users) + 
  geom_point(alpha=0.3, fill="blue", color="blue")


grid.arrange(p1, p2, ncol=2)
```


It has a very low correlation:
```{r}
cor(x=fb_data$category, y=fb_data$lifetime_engaged_users)
```


#### Type

This is the type of the post, either Link, Photo, Status or Video. People mostly post photos:

```{r}
p1 = fb_data %>% ggplot() + 
  aes(x=type) + 
  geom_bar(width=0.5, alpha=0.5, fill="blue", color="blue")

p2 = fb_data %>% ggplot() + 
  aes(x=type, y=lifetime_engaged_users) + 
  geom_point(alpha=0.3, fill="blue", color="blue")

grid.arrange(p1, p2, ncol=2)
```

#### Month

Month when the post was published (1-12). The company mostly posted in October:

```{r}
fb_data %>% ggplot() + 
  aes(x=post_month) + 
  geom_bar(width=0.5, alpha=0.5, fill="blue", color="blue")
```


#### Day of week

Day of the week when the post was published (1-7, 1=Sunday). The company posted mostly during Fri and Sat:

```{r}
fb_data %>% ggplot() + 
  aes(x=post_wkday) + 
  geom_bar(width=0.5, alpha=0.5, fill="blue", color="blue")
```


#### Post hour

The hour of the day the post was published (1-24). Compay posted mostly at 3am and 10am:

```{r}
fb_data %>% ggplot() + 
  aes(x=post_hour) + 
  geom_bar(width=0.5, alpha=0.5, fill="blue", color="blue")
```


## Models

Before fitting the models, we need to remove NA's, as those bring issues down the line. The only variable with NA's we will include in the model is `paid`:

```{r}
fb_data_mod = fb_data %>%
  filter(!is.na(paid))
```

### Basic model

First we will try the basic model:

```{r}
model1 = lm(I(log(lifetime_engaged_users)) ~ 1 + day_period, data=fb_data_mod)
summary(model1, vcov=vcovHC(model1, type="HC1"))
```

The evening period is only significant to the 0.1 level. We'll see the signficance with robust SEs:

```{r}
coeftest(model1, vcov=vcovHC(model1, type="HC1"))
```

The coefficients are now all signficant to the 0.05 level. 

#### Assumptions

Because we have more than 100 observations, we can apply the Large-Sample assumptions that are mainly 2:
    - IID: This requisite is never completely satisfied, and this dataset is not the exception. The interactions of post in the past may affect newer posts for example. For the purposes of this analysis though, and following the analysis of Moro et al., we will assume that doesn't impede proceeding further with the study.
    - BLP exists: The main requirement for this is that no perfect collinearity exists. R hasn't dropped any variables from the model or failed to run the regression, which is a sign that perfect collinearity doesn't exit.
    
Even though we only need those, we could check the other CLM requirements:

    - Normal errors: Errors seem to be left skewed.

```{r}
fb_data_mod %>%
  mutate(
    mod1_predict = predict(model1),
    mod1_resid = resid(model1)
  ) %>%
  ggplot(aes(x=mod1_resid)) + geom_histogram()
```

```{r}
fb_data_mod %>%
  mutate(
    mod1_predict = predict(model1),
    mod1_resid = resid(model1)
  ) %>%
  ggplot(aes(sample=mod1_resid)) + stat_qq() + stat_qq_line()
```


    - Linearity of expectations & Homoscedasticity: We can test this by looking into the Predicted vs Residuals graph. From the graph we see that a line might fit the relationship between the variables, but it is probably not homoscedastic.
    
```{r}
fb_data_mod %>%
  mutate(
    mod1_predict = predict(model1),
    mod1_resid = resid(model1)
  ) %>%
  ggplot(aes(x=mod1_predict, y=mod1_resid)) + geom_point() + geom_smooth()
```

We can test for homoscedasticity formally, and we found that the data is much likely NOT homoscedastic:

```{r}
library(lmtest)
bptest(model1)
```


    
### Adding Month and Weekday

We can now run another model that includes the time of the day and month as factors. This mainly to control for how the people may behave in different times of the year. These variables will be included as factors, as their interpretation is not metric:

```{r}
model2 = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + factor(post_month) + factor(post_wkday)
                         , data=fb_data_mod)
coeftest(model2, vcov=vcovHC(model2, type="HC1"))
```

Hmmm...doing so makes our variables not significant, which may be a problem.

Let's try to add only wkday first:

```{r}
model3 = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + factor(post_wkday)
                         , data=fb_data_mod)
coeftest(model3, vcov=vcovHC(model3, type="HC1"))
```

Seems like weekday doesn't add a lot of context, none of the coefficients are significant. Running an F-test reveals the same:

```{r}
waldtest(model1, model3, vcov=vcovHC(model3, type="HC1"))
```

Let's see month:

```{r}
model4 = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + factor(post_month)
                         , data=fb_data_mod)
coeftest(model4, vcov=vcovHC(model4, type="HC1"))
```

Ok, so month is the variable introducing all these changes. An F-test indicates that the model is appropriate. Should we include `month` in the analysis then?

```{r}
waldtest(model1, model4, vcov=vcovHC(model4, type="HC1"))
```


### Adding Paid, Type and Category

Now we want to add paid, type and category:

```{r}
model5 = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + paid + factor(category) + type
                         , data=fb_data_mod)
coeftest(model5, vcov=vcovHC(model5, type="HC1"))
```

All variables are significant. Coefficients remain robust to new variables, keeping a similar sign and magnitude.

Run an F-test to see if the model is worth it and it is to the 0.05 level:

```{r}
waldtest(model1, model5, vcov=vcovHC(model5, type="HC1"))
```



### Summary so far

Take into account this table doesn't have robust SEs:

```{r}
stargazer(
  model1, model2, model3, model4, model5,
  type="text"
)
```


One issue we have with this is that we have a very low R2 (~10%). We need another variable that can explain this better.


### Add Brand Awareness

```{r}
model6 = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + 
                           paid + factor(category) + type +
                           page_ttl_likes
                         , data=fb_data_mod)
coeftest(model6, vcov=vcovHC(model6, type="HC1"))
```


The variable comes in very significant and reduces all the other coefficients significantly and the model is appropriate:

```{r}
waldtest(model5, model6, vcov=vcovHC(model6, type="HC1"))
```

The R2 improves significantly, but it is still low (~25%):
```{r}
summary(model6)
```



### Include ALL

One last test including all the variables we discussed:

```{r}
model_all = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + 
                           factor(post_month) + factor(post_wkday) +
                           paid + factor(category) + type +
                           page_ttl_likes
                         , data=fb_data_mod)
coeftest(model_all, vcov=vcovHC(model_all, type="HC1"))
```



```{r}
model_inter = lm(I(log(lifetime_engaged_users)) ~ 1 + 
                           day_period + 
                           paid + factor(category) + type +
                           page_ttl_likes + factor(category)*type
                         , data=fb_data_mod)
coeftest(model_inter, vcov=vcovHC(model_inter, type="HC1"))
```



```{r}
waldtest(model5, model_inter, vcov=vcovHC(model_inter, type="HC1"))
```

